{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Распознавание_слов_из_фразы.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs4j3DSoMnep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# перезагрузить ноутбук\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w4tQsIFMsc0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrSoPHm55snj",
        "colab_type": "text"
      },
      "source": [
        "# Определяет слова из фразы. \n",
        "Загружаем фразу и путь к ней из директория Words_from_streams\n",
        "\n",
        "Если слово из фразы - одно из списка: 'yes','no','up','down','left','right','stop','go','on','off' - программа должна его опознать: \n",
        "\n",
        "My prediction for 1_no_bed_bird.wav is...\n",
        "no\n",
        "\n",
        "В противном случае программа должна сказать:\n",
        "\n",
        "My prediction for 3_no_bed_bird.wav is...\n",
        "UNKNOWN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Используется модель '/content/Simple-Speech-Command-Algorithm/models','model1_dr0.25_lr0.1_ra0.hdf5'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW2GwtmLNkP2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj7ERdkwgQ0n",
        "colab_type": "text"
      },
      "source": [
        "Копирование файлов с Git на локальный диск виртуальной машины - вставка ссылки с гитхаба: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOLXvPzApR-o",
        "colab_type": "code",
        "outputId": "3752686f-cdf9-4faa-c3a3-665d53bf825a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/smartsinovich/Simple-Audio-Recognition.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Simple-Audio-Recognition'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 335 (delta 61), reused 50 (delta 14), pack-reused 215\u001b[K\n",
            "Receiving objects: 100% (335/335), 5.02 MiB | 18.71 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy2vS167PVSg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Final Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_gaW0COVMSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This algorithm is a simple command recognition algorithm designed to allow hobbyists and students to build a speech recognition\n",
        "# component into their own projects. This algorithm takes two parameters - a path to an audio file, and an audio file name - and\n",
        "# returns 1 of 11 classifications based upon the contents of the audio file. 10 of those classifications are simple speech \n",
        "# commands - 'yes','no','up','down','left','right','stop','go','on','off' - while the 11th classification is a catchall 'unknown'\n",
        "# category.\n",
        "\n",
        "# Valid audio files for this algorithm have a 16000hz sample rate and a maximum duration of 1 second. \n",
        "# Audio files are decoded into 16 bit samples.\n",
        "\n",
        "# The algorithm was trained and tested with 16 bit samples using the Speech Commands Dataset released by Google on August 3, 2017. The \n",
        "# data contains 64,727 one-second 16000hz audio clips of 30 short words. The audio files were crowdsourced by Google with the goal \n",
        "# of collecting single-word commands (rather than words as said and used in conversation). \n",
        "\n",
        "# RUN THIS CELL TO LOAD ALGORITHM INTO IPYTHON KERNEL\n",
        "\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "from scipy.fftpack import dct\n",
        "import numpy as np\n",
        "import keras\n",
        "import math\n",
        "from keras.models import load_model\n",
        "\n",
        "def speech_command_algo(audio_path, filename):\n",
        "    #print(\"My prediction for \"+filename+\" is...\")\n",
        "    model_path = os.path.join(os.path.dirname(os.path.abspath('__file__')),\n",
        "                              '/content/Simple-Audio-Recognition/Models',\n",
        "                              'model1_dr0.25_lr0.1_ra0.hdf5')  # путь к модели и модель\n",
        "    \n",
        "    \n",
        "    model = load_model(model_path)\n",
        "    mfccs = mfcc_conversion(audio_path, filename).reshape((1,79,12))\n",
        "    prediction = np.argmax(model.predict(mfccs))\n",
        "    print(\"My prediction for \"+filename+\" is...\") \n",
        "    if prediction == 1:\n",
        "        prediction = \"yes\"\n",
        "    elif prediction == 2:\n",
        "        prediction = \"no\"\n",
        "    elif prediction == 3:\n",
        "        prediction = \"up\"\n",
        "    elif prediction == 4:\n",
        "        prediction = \"down\"\n",
        "    elif prediction == 5:\n",
        "        prediction = \"left\"\n",
        "    elif prediction == 6:\n",
        "        prediction = \"right\"\n",
        "    elif prediction == 7:\n",
        "        prediction = \"on\"\n",
        "    elif prediction == 8:\n",
        "        prediction = \"off\"\n",
        "    elif prediction == 9:\n",
        "        prediction = \"stop\"\n",
        "    elif prediction == 10:\n",
        "        prediction = \"go\"\n",
        "    else:\n",
        "        prediction = \"UNKNOWN\"\n",
        "    print(prediction)\n",
        "    \n",
        "# given a filename, mfcc_conversion returns mel frequency cepstral coefficients array\n",
        "# mfcc_conversion returns array of (79,12) representing 79 audio frames described by 12 coefficients\n",
        "def mfcc_conversion(audio_path, filename, sample_rate = 16000, frame_size = 400, stride_size = 200, nfft = 512):\n",
        "    # decode audio\n",
        "    decoded_audio = audio_decoder(str(os.path.join(audio_path, filename)))    \n",
        "    audio = decoded_audio.reshape((16000,1))\n",
        "    \n",
        "    first_index = 0\n",
        "    mfcc_coefficients = np.empty((0,12))\n",
        "    # apply the following for each signal frame\n",
        "    while first_index <= audio.shape[0]-frame_size:\n",
        "        last_index = first_index+frame_size\n",
        "        frame = audio[first_index:last_index,:]\n",
        "        \n",
        "        # calculate discrete Fourier transform\n",
        "        frame = np.fft.fft(frame, n = nfft, axis=0)\n",
        "        \n",
        "        # calculate the periodogram estimate of the power spectrum; drop last half of values\n",
        "        power_spectrum = np.absolute(np.square(frame))/frame_size\n",
        "        power_spectrum = power_spectrum[0:int(nfft/2),:].astype(float)\n",
        "        power_spectrum = power_spectrum.reshape((power_spectrum.shape[0],))\n",
        "        # print(power_spectrum)\n",
        "        \n",
        "        # apply the mel filterbank to the power spectra, sum the energy in each filter\n",
        "            # frequencies on which to define mel filterbanks\n",
        "        mel_freqs = np.array([300, 383.4, 473.8, 571.7, 677.8, 792.7, 917.3, 1052.2, 1198.3, 1356.7, 1528.3,\n",
        "                              1714.2, 1915.6, 2133.7, 2370.1, 2626.3, 2903.7, 3204.4, 3530.1, 3882.9, 4265.2,\n",
        "                              4679.4, 5128.2, 5614.4, 6141.1, 6711.8, 7330.1, 8000]).astype(float)\n",
        "        vfunc = np.vectorize(bin_index)\n",
        "        mel_bins = vfunc(mel_freqs, nfft=nfft, sample_rate=16000)\n",
        "        # print(mel_bins)\n",
        "        \n",
        "            # calculate filterbank\n",
        "        mel_filterbank = np.empty((26,256))\n",
        "        for i in range(0,mel_filterbank.shape[0]):\n",
        "            for j in range(0,mel_filterbank.shape[1]):\n",
        "                mel_bin_min = mel_bins[i]\n",
        "                mel_bin_mid = mel_bins[i+1]\n",
        "                mel_bin_max = mel_bins[i+2]\n",
        "                if j >= mel_bin_min and j < mel_bin_mid:\n",
        "                    filter = float(j - mel_bin_min) / float(mel_bin_mid - mel_bin_min)\n",
        "                elif j >= mel_bin_mid and j < mel_bin_max:\n",
        "                    filter = float(mel_bin_max- j) / float(mel_bin_max - mel_bin_mid)\n",
        "                else:\n",
        "                    filter = float(0)\n",
        "                mel_filterbank[i,j] = filter\n",
        "                \n",
        "                # apply filterbank to power spectra and calculate log filterbank energies\n",
        "        logbankenergies = np.zeros((mel_filterbank.shape[0]))\n",
        "        for i in range(0, mel_filterbank.shape[0]):\n",
        "            mel_filters = mel_filterbank[i,:]\n",
        "            bankenergy = np.dot(power_spectrum,mel_filters)+1\n",
        "            logbankenergies[i] = np.log(bankenergy)\n",
        "            \n",
        "        \n",
        "        # take the discrete cosine transform of the log filterbank energies\n",
        "        log_dct = dct(logbankenergies)\n",
        "        \n",
        "        # saving DCT coefficients 2-13; discard rest\n",
        "        log_dct = np.transpose(log_dct[1:13])\n",
        "        i = first_index/stride_size\n",
        "        mfcc_coefficients = np.vstack((mfcc_coefficients, log_dct))\n",
        "                \n",
        "        # set up next frame\n",
        "        first_index = first_index + stride_size\n",
        "    \n",
        "    return mfcc_coefficients\n",
        "\n",
        "# calculates bin index given frequency and sample_rate\n",
        "def bin_index(frequency, nfft=512, sample_rate=16000):\n",
        "    bin = math.floor((nfft+1)*frequency/sample_rate)\n",
        "    return bin\n",
        "\n",
        "# decodes audio given a file name\n",
        "def audio_decoder(filename):\n",
        "    rate, data = wavfile.read(filename)\n",
        "    data = np.array(data)\n",
        "    if data.shape[0]<=16000:\n",
        "        difference = 16000 - data.shape[0]\n",
        "        data = np.append(data,np.zeros((difference,)))\n",
        "        data = np.transpose(data.reshape((16000,1)))\n",
        "        data = data.astype(int)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIYtYp9w-b0A",
        "colab_type": "code",
        "outputId": "986687df-57b4-4ed3-b955-e31939c7806d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Загружаем фразу и путь к ней\n",
        "#sample_phrase = '3_no_bed_bird.wav'\n",
        "#dir_phrase = '/content/Simple-Audio-Recognition/Words_from_streams/ML_no_bed_bird'\n",
        "dir_phrase = '/content/Simple-Audio-Recognition/Words_from_streams/ML_bed_bird_right'\n",
        "\n",
        "\n",
        "\n",
        "dir_path = os.path.join(os.path.dirname(os.path.abspath('__file__')), dir_phrase)\n",
        "files = os.listdir(dir_path)\n",
        "sample_files = [i for i in files if i.endswith('.wav')]\n",
        "print(sample_files)\n",
        "\n",
        "for sample_file in sample_files:\n",
        "    speech_command_algo(dir_path,sample_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ML_1_bed_bird_right.wav', 'ML_2_bed_bird_right.wav', 'ML_3_bed_bird_right.wav']\n",
            "My prediction for ML_1_bed_bird_right.wav is...\n",
            "UNKNOWN\n",
            "My prediction for ML_2_bed_bird_right.wav is...\n",
            "UNKNOWN\n",
            "My prediction for ML_3_bed_bird_right.wav is...\n",
            "right\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PvQOVdwMhJN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}